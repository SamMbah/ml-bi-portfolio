{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9e247e7",
   "metadata": {},
   "source": [
    "# Section 1:  Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c60ea85c",
   "metadata": {},
   "source": [
    "## Importing standard python libraries\n",
    "To carry out this task, we need to import the required standard python default libraries needed to carry out the task e.g\n",
    "\n",
    "`import csv`, \n",
    "`import json`,\n",
    "`from datetime import datetime`\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c9d499e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv #This will help us extract the data in the csv file and read in the ACW csv file\n",
    "import json # This will help us to read and write json files\n",
    "from datetime import datetime # Manipulation of date and time objects can be done using the datetime library\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3daae833",
   "metadata": {},
   "source": [
    "## Reading in the data and observing the headers\n",
    "\n",
    "After the importation of our required libraries, this section will be to read in our csv file e.g `with open(\"acw_user_data.csv\")` and observe the headers of our csv file in order to easily index each column head of our csv file in our subsequent manipulations of our data. A list comprehension has been used to create a list for the headers e.g ``` [x for x in iterable if condition]```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ad686bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Address Street', 'Address City', 'Address Postcode', 'Age (Years)', 'Distance Commuted to Work (miles)', 'Employer Company', 'Credit Card Start Date', 'Credit Card Expiry Date', 'Credit Card Number', 'Credit Card CVV', 'Dependants', 'First Name', 'Bank IBAN', 'Last Name', 'Marital Status', 'Yearly Pension (GBP)', 'Retired', 'Yearly Salary (GBP)', 'Sex', 'Vehicle Make', 'Vehicle Model', 'Vehicle Year', 'Vehicle Type']]\n"
     ]
    }
   ],
   "source": [
    "with open(\"acw_user_data.csv\") as acw_users: #Opening the CSV file to be read in the data\n",
    "    acw_user_data= csv.reader(acw_users) #Using one of the concepts of CSV to read in the file\n",
    "    #The loop iterates over each row and assigns the index of each row to user_index and the data of each index to user_data\n",
    "    #A list comprehension is used to create the acw_user_header using less blocks of code\n",
    "    acw_user_header =[user_col for user_row, user_col in enumerate(acw_user_data) if user_row == 0]\n",
    "print(acw_user_header) #Using the print function to visualize the acw_user_header\n",
    "           "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e14725",
   "metadata": {},
   "source": [
    "## Casting of data types and re-ordering of the key-value pairs \n",
    "Carried out the required conversion of all flat structures into nested structures and also casted all data types to their various format e.g `int`,`float`,`bool`, in the process of casting to the various datatypes, a reordering of the key-value pairs was done in order to have a well-organized data structure and handling errors that could prevent casting the datatypes format while parsing the values to a list using the list comprehension method e.g ``` [x for x in iterable]```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0c5a6df4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problematic rows for dependants in casting empty strings\n"
     ]
    }
   ],
   "source": [
    "with open(\"acw_user_data.csv\") as acw_user: # Opening the csv file to read in the data\n",
    "    acw_user_data= csv.reader(acw_user) #Using one of the methods of csv to read in the data\n",
    "    #Re-ordered the key-value pairs of the acw_user_data and created a new list using list comprehension method\n",
    "    try:\n",
    "        acw_data_list = [{'First Name':str(user_column[11]),\n",
    "                      'Last Name':str(user_column[13]),\n",
    "                      'Age':int(user_column[3]),\n",
    "                      'Sex':str(user_column[18]),\n",
    "                      'Retired':(user_column[16].lower()== 'true'),\n",
    "                      'Marital-status':str(user_column[14]),\n",
    "                      'Yearly Salary (GBP)':float(user_column[17]),\n",
    "                       'Yearly Pension (GBP)':float(user_column[15]),\n",
    "                       'Company':str(user_column[5]),\n",
    "                       'Commute Distance':float(user_column[4]),\n",
    "                       'Vehicle':{'Make':str(user_column[19]),\n",
    "                       'Model': str(user_column[20]),\n",
    "                       'Year':int(user_column[21]),\n",
    "                       'Type':str(user_column[22])    \n",
    "            },\n",
    "            'CreditCard':{ 'Start-date':str(user_column[6]),\n",
    "                         'End-date':str(user_column[7]),\n",
    "                         'Number':int(user_column[8]),\n",
    "                         'CCV':int(user_column[9]),\n",
    "                         'IBAN':str(user_column[12])    \n",
    "            },\n",
    "            'Dependants': (int(user_column[10])),\n",
    "            'Address': {'Street':str(user_column[0]),\n",
    "                         'City':str(user_column[1]),\n",
    "                         'Postcode':str(user_column[2])    \n",
    "              } \n",
    "        } for user_row,user_column in enumerate(acw_user_data) if user_row !=0]\n",
    "    except ValueError:\n",
    "        print(\"Problematic rows for dependants in casting empty strings\")\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91f0275",
   "metadata": {},
   "source": [
    "## Resolving errors in the dependants column\n",
    "A list has been created in identifying problematic rows for dependants using some conditions e.g ``` [x for x in iterable if condition]```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e16bce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Problematic rows for Dependents in row 23', 'Problematic rows for Dependents in row 111', 'Problematic rows for Dependents in row 181', 'Problematic rows for Dependents in row 207', 'Problematic rows for Dependents in row 272', 'Problematic rows for Dependents in row 274', 'Problematic rows for Dependents in row 276', 'Problematic rows for Dependents in row 360', 'Problematic rows for Dependents in row 462', 'Problematic rows for Dependents in row 470', 'Problematic rows for Dependents in row 581', 'Problematic rows for Dependents in row 638', 'Problematic rows for Dependents in row 681', 'Problematic rows for Dependents in row 727', 'Problematic rows for Dependents in row 824', 'Problematic rows for Dependents in row 867', 'Problematic rows for Dependents in row 919', 'Problematic rows for Dependents in row 933', 'Problematic rows for Dependents in row 985']\n"
     ]
    }
   ],
   "source": [
    "with open(\"acw_user_data.csv\") as acw_user: #Opening the file to read it in\n",
    "    acw_user_data= csv.reader(acw_user)#Reading the file  using a csv method\n",
    "    #Created a list for the problematic rows for dependants using the list comprehension while placing some conditions\n",
    "    Problematic_rows_for_dependents = [f\"Problematic rows for Dependents in row {user_row + 1}\" \n",
    "                                       for user_row, user_column in enumerate(acw_user_data) \n",
    "                                       if user_column[10] == \"\"  or  user_column[10] == \" \"]\n",
    "\n",
    "print(Problematic_rows_for_dependents) #Printed out the list to visualize problematic rows for dependants"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60572e33",
   "metadata": {},
   "source": [
    " ## Replacing problematic rows for dependants with meaning values \n",
    "The problematic rows for dependants will be replaced with the value `0` when encountered to ensure conversion from task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d3a03ff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "1\n",
      "2\n",
      "2\n",
      "3\n",
      "2\n",
      "3\n",
      "3\n",
      "4\n",
      "2\n",
      "3\n",
      "2\n",
      "3\n",
      "2\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "3\n",
      "2\n",
      "1\n",
      "2\n",
      "1\n",
      "5\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "4\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "1\n",
      "3\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "4\n",
      "4\n",
      "2\n",
      "1\n",
      "5\n",
      "4\n",
      "2\n",
      "2\n",
      "2\n",
      "1\n",
      "3\n",
      "2\n",
      "5\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "2\n",
      "5\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "1\n",
      "1\n",
      "3\n",
      "2\n",
      "1\n",
      "3\n",
      "1\n",
      "3\n",
      "2\n",
      "1\n",
      "1\n",
      "4\n",
      "4\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "0\n",
      "2\n",
      "2\n",
      "1\n",
      "1\n",
      "3\n",
      "1\n",
      "1\n",
      "3\n",
      "3\n",
      "5\n",
      "4\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "3\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "2\n",
      "3\n",
      "2\n",
      "1\n",
      "3\n",
      "1\n",
      "5\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "1\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "4\n",
      "1\n",
      "1\n",
      "2\n",
      "4\n",
      "3\n",
      "2\n",
      "3\n",
      "3\n",
      "1\n",
      "2\n",
      "3\n",
      "2\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "5\n",
      "3\n",
      "2\n",
      "1\n",
      "1\n",
      "3\n",
      "0\n",
      "2\n",
      "2\n",
      "3\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "1\n",
      "2\n",
      "2\n",
      "5\n",
      "3\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "1\n",
      "4\n",
      "1\n",
      "2\n",
      "3\n",
      "2\n",
      "2\n",
      "2\n",
      "0\n",
      "2\n",
      "1\n",
      "3\n",
      "1\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "1\n",
      "3\n",
      "2\n",
      "2\n",
      "2\n",
      "4\n",
      "1\n",
      "2\n",
      "3\n",
      "3\n",
      "2\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "4\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "1\n",
      "1\n",
      "2\n",
      "3\n",
      "2\n",
      "2\n",
      "1\n",
      "3\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "1\n",
      "3\n",
      "1\n",
      "2\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "2\n",
      "0\n",
      "3\n",
      "0\n",
      "2\n",
      "0\n",
      "3\n",
      "3\n",
      "2\n",
      "2\n",
      "3\n",
      "4\n",
      "1\n",
      "2\n",
      "1\n",
      "5\n",
      "2\n",
      "3\n",
      "3\n",
      "2\n",
      "4\n",
      "3\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "1\n",
      "3\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "3\n",
      "5\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "3\n",
      "1\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "3\n",
      "5\n",
      "3\n",
      "2\n",
      "1\n",
      "1\n",
      "4\n",
      "2\n",
      "2\n",
      "1\n",
      "3\n",
      "2\n",
      "2\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "1\n",
      "4\n",
      "2\n",
      "3\n",
      "2\n",
      "3\n",
      "2\n",
      "2\n",
      "3\n",
      "4\n",
      "1\n",
      "2\n",
      "2\n",
      "1\n",
      "1\n",
      "4\n",
      "1\n",
      "2\n",
      "3\n",
      "0\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "1\n",
      "3\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "2\n",
      "5\n",
      "2\n",
      "1\n",
      "1\n",
      "4\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "1\n",
      "5\n",
      "2\n",
      "3\n",
      "1\n",
      "1\n",
      "2\n",
      "5\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "4\n",
      "2\n",
      "3\n",
      "1\n",
      "2\n",
      "4\n",
      "3\n",
      "1\n",
      "3\n",
      "2\n",
      "5\n",
      "3\n",
      "2\n",
      "5\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "2\n",
      "3\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "1\n",
      "3\n",
      "1\n",
      "3\n",
      "1\n",
      "1\n",
      "1\n",
      "5\n",
      "3\n",
      "4\n",
      "2\n",
      "2\n",
      "4\n",
      "1\n",
      "4\n",
      "1\n",
      "2\n",
      "3\n",
      "1\n",
      "1\n",
      "0\n",
      "2\n",
      "1\n",
      "4\n",
      "5\n",
      "1\n",
      "2\n",
      "1\n",
      "0\n",
      "2\n",
      "2\n",
      "3\n",
      "2\n",
      "3\n",
      "1\n",
      "1\n",
      "2\n",
      "3\n",
      "3\n",
      "2\n",
      "3\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "3\n",
      "2\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "3\n",
      "2\n",
      "4\n",
      "1\n",
      "2\n",
      "2\n",
      "1\n",
      "3\n",
      "2\n",
      "2\n",
      "4\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "5\n",
      "3\n",
      "1\n",
      "5\n",
      "2\n",
      "3\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "2\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "3\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "1\n",
      "1\n",
      "3\n",
      "0\n",
      "2\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "2\n",
      "4\n",
      "2\n",
      "2\n",
      "2\n",
      "1\n",
      "1\n",
      "2\n",
      "3\n",
      "2\n",
      "1\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "2\n",
      "1\n",
      "1\n",
      "2\n",
      "4\n",
      "1\n",
      "2\n",
      "3\n",
      "2\n",
      "1\n",
      "3\n",
      "2\n",
      "1\n",
      "1\n",
      "2\n",
      "3\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "1\n",
      "3\n",
      "3\n",
      "3\n",
      "2\n",
      "4\n",
      "2\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "2\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "1\n",
      "2\n",
      "5\n",
      "2\n",
      "1\n",
      "3\n",
      "2\n",
      "2\n",
      "3\n",
      "1\n",
      "3\n",
      "1\n",
      "2\n",
      "3\n",
      "2\n",
      "2\n",
      "1\n",
      "5\n",
      "1\n",
      "1\n",
      "3\n",
      "1\n",
      "2\n",
      "2\n",
      "1\n",
      "3\n",
      "3\n",
      "2\n",
      "2\n",
      "0\n",
      "2\n",
      "2\n",
      "2\n",
      "1\n",
      "3\n",
      "1\n",
      "2\n",
      "2\n",
      "1\n",
      "1\n",
      "4\n",
      "2\n",
      "1\n",
      "3\n",
      "2\n",
      "2\n",
      "4\n",
      "3\n",
      "1\n",
      "3\n",
      "2\n",
      "1\n",
      "3\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "1\n",
      "4\n",
      "1\n",
      "2\n",
      "3\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "2\n",
      "4\n",
      "3\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "4\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "5\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "2\n",
      "2\n",
      "3\n",
      "4\n",
      "2\n",
      "3\n",
      "2\n",
      "3\n",
      "2\n",
      "5\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "3\n",
      "5\n",
      "2\n",
      "2\n",
      "1\n",
      "1\n",
      "4\n",
      "1\n",
      "5\n",
      "2\n",
      "4\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "5\n",
      "2\n",
      "1\n",
      "2\n",
      "4\n",
      "1\n",
      "2\n",
      "3\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "5\n",
      "4\n",
      "2\n",
      "1\n",
      "2\n",
      "4\n",
      "3\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "3\n",
      "2\n",
      "1\n",
      "2\n",
      "3\n",
      "5\n",
      "3\n",
      "2\n",
      "3\n",
      "1\n",
      "4\n",
      "2\n",
      "0\n",
      "1\n",
      "5\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "5\n",
      "3\n",
      "2\n",
      "3\n",
      "2\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "1\n",
      "4\n",
      "2\n",
      "2\n",
      "3\n",
      "2\n",
      "3\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "1\n",
      "4\n",
      "3\n",
      "4\n",
      "2\n",
      "4\n",
      "2\n",
      "2\n",
      "3\n",
      "2\n",
      "2\n",
      "1\n",
      "1\n",
      "0\n",
      "2\n",
      "2\n",
      "2\n",
      "1\n",
      "1\n",
      "2\n",
      "4\n",
      "1\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "1\n",
      "2\n",
      "5\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "3\n",
      "3\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "4\n",
      "1\n",
      "2\n",
      "3\n",
      "2\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "2\n",
      "0\n",
      "2\n",
      "1\n",
      "3\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "2\n",
      "2\n",
      "5\n",
      "3\n",
      "2\n",
      "0\n",
      "5\n",
      "2\n",
      "4\n",
      "2\n",
      "1\n",
      "3\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "3\n",
      "1\n",
      "1\n",
      "3\n",
      "1\n",
      "1\n",
      "3\n",
      "3\n",
      "2\n",
      "1\n",
      "3\n",
      "2\n",
      "2\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "2\n",
      "3\n",
      "2\n",
      "4\n",
      "3\n",
      "2\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "0\n",
      "4\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "3\n",
      "2\n",
      "2\n",
      "1\n",
      "3\n",
      "1\n",
      "Problematic dependants rows have been fixed\n"
     ]
    }
   ],
   "source": [
    "with open(\"acw_user_data.csv\") as acw_user: # Opening the csv file to read in the data\n",
    "    acw_user_data= csv.reader(acw_user) #Using one of the methods of csv to read in the data\n",
    "    #Resolved the problematic rows for dependants in our data by replacing empty strings with 0\n",
    "    acw_data_list = [{'First Name':str(user_column[11]),\n",
    "                      'Last Name':str(user_column[13]),\n",
    "                      'Age':int(user_column[3]),\n",
    "                      'Sex':str(user_column[18]),\n",
    "                      'Retired':(user_column[16].lower()== 'true'),\n",
    "                      'Marital-status':str(user_column[14]),\n",
    "                      'Yearly Salary (GBP)':float(user_column[17]),\n",
    "                       'Yearly Pension (GBP)':float(user_column[15]),\n",
    "                       'Company':str(user_column[5]),\n",
    "                       'Commute Distance':float(user_column[4]),\n",
    "                       'Vehicle':{'Make':str(user_column[19]),\n",
    "                       'Model': str(user_column[20]),\n",
    "                       'Year':int(user_column[21]),\n",
    "                       'Type':str(user_column[22])    \n",
    "            },\n",
    "            'CreditCard':{ 'Start-date':str(user_column[6]),\n",
    "                         'End-date':str(user_column[7]),\n",
    "                         'Number':int(user_column[8]),\n",
    "                         'CCV':int(user_column[9]),\n",
    "                         'IBAN':str(user_column[12])    \n",
    "            },\n",
    "            'Dependants': (int(user_column[10])if user_column[10] !=\"\" and user_column[10] !=\" \" else 0),\n",
    "            'Address': {'Street':str(user_column[0]),\n",
    "                         'City':str(user_column[1]),\n",
    "                         'Postcode':str(user_column[2])    \n",
    "              } \n",
    "        } for user_row,user_column in enumerate(acw_user_data) if user_row != 0]\n",
    "\n",
    "for user_column in acw_data_list:#Iterating over our acw_data_list to view the fixed dependants column\n",
    "        print(user_column['Dependants'])#printed out the dependant column to observe changes made to the dependants column\n",
    "print('Problematic dependants rows have been fixed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d2499be2",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (Temp/ipykernel_12412/1163018850.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\HP\\AppData\\Local\\Temp/ipykernel_12412/1163018850.py\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    if user_col[10] !=\"\" and user_col[10] !=\" \" else 0\u001b[0m\n\u001b[1;37m                                                ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "if user_col[10] !=\"\" and user_col[10] !=\" \" else 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32804356",
   "metadata": {},
   "source": [
    "## Writing all records to a processed.json file in the JSON data format \n",
    "All records were converted to json strings using `json.dumps` and then, writing all records to the new file `Processed.json` using `json.dump` also, the data was loaded using the json method `json.load`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b0d74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_object = json.dumps(acw_data_list) #Created a json string using the json method json.dumps\n",
    "with open('Processed.json', mode='w') as json_file:#Opened up the Processed.json file in the write mode to parse in the json string\n",
    "    json.dump(processed_object, json_file) #Parsed in the json string using a json method json.dump\n",
    "with open('Processed.json', mode='r') as json_file:#Opened up the Processed.json in the read mode\n",
    "    print(json.load(json_file)) #Used a json method  json.load the load in the file which contains the parsed json string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d50a10",
   "metadata": {},
   "source": [
    "## Creation of additional files \n",
    "Additional files for `retired.json` and `employed.json` have been created as requested by the employer. A list comprehension method has been used to create  lists for the additional files e.g ``` [x for x in iterable if condition]``` which are converted to json strings using the `json.dumps` method and writing the json strings to thier various files using the json method `json.dump`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca056b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retired employees data captured using a list comprehension to create a list of retired employees\n",
    "Retired_data = [retired for retired in acw_data_list if retired['Retired'] == True]\n",
    "#employed data captured using a list comprehension to create a list of employed\n",
    "employed_data = [retired for retired in acw_data_list if retired['Retired'] == False]\n",
    "Retired_json_dumps = json.dumps(Retired_data) #converted the retired data to a json string\n",
    "employed_json_dumps = json.dumps(employed_data)#converted the employed data to a json string\n",
    "with open('retired.json', mode='w') as retired_json:#Opened the retired json file in the write mode\n",
    "    json.dump(Retired_json_dumps, retired_json)#Parsed in the json string of those who have retired\n",
    "with open('employed.json', mode='w') as employed_json:#Opened the retired json file in the write mode\n",
    "    json.dump(employed_json_dumps, employed_json)#Parsed in the json string of those who are employed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7833692b",
   "metadata": {},
   "source": [
    "\n",
    "## Writing a function to resolve some issues with credit card entries \n",
    "6. Using the imported `datetime` library,for manipulation of dates and time object, a function that takes care of those issues \n",
    "with credit card entries have been put in place e.g \n",
    "\n",
    "\n",
    "\n",
    "`def  remove_ccard(user_col):\n",
    "    Start_date = datetime.strptime(user_col['CreditCard']['Start-date'], '%m/%y')\n",
    "    End_date = datetime.strptime(user_col['CreditCard']['End-date'], '%m/%y')\n",
    "    diff_in_years = End_date.year - Start_date.year\n",
    "    if diff_in_years > 10:\n",
    "        return True\n",
    "    else:\n",
    "        return False `\n",
    "        \n",
    "The `datetime` library ensured that the dates in the Creditcard column are parsed to the `datetime` format, a list was created for the cards to be removed and then converted to a json string using `json.dumps` method and eventually, writing the converted file to the json file `remove_ccard.json`\n",
    "        \n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25563dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def  remove_ccard(user_col): #Defined a function to remove the cards with issues\n",
    "    Start_date = datetime.strptime(user_col['CreditCard']['Start-date'], '%m/%y')# converted the Creditcard column date format to the datetime library format\n",
    "    End_date = datetime.strptime(user_col['CreditCard']['End-date'], '%m/%y')# converted the Creditcard column date format to the datetime library format\n",
    "    diff_in_years = End_date.year - Start_date.year # Created a variable to hold the difference betwen startdate and enddate\n",
    "    if diff_in_years > 10:#Stated a filtering condtion on the date difference\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "#Created a list to hold the data of cards to be removed\n",
    "remove_cards_list = [user_col for user_col in acw_data_list if remove_ccard(user_col) == True]\n",
    "#Converted the list created to a json string\n",
    "remove_cards_json = json.dumps(remove_cards_list)\n",
    "with open('remove_ccard.json', mode='w') as remove_cards_file:#Opening the file in the write mode\n",
    "    json.dump(remove_cards_json, remove_cards_file)#Writes the json string into the remove card file\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aabc6e8",
   "metadata": {},
   "source": [
    "## Some additional metrics which will be used for ranking customers\n",
    "Created a salary-commute file to hold the list of distance taken to earn a certain salary, then opened the file using `with open('Processed.json') as processed_file`, added a new `key` which is `salary-Commute Per Mile` while filtering our data using some conditons, proceeded in defining a function `def sort_salary_commute(user_col):\n",
    "    return user_col[\"Salary-Commute Per Mile\"]` and then, sorted the data using the `sorted` function, after sorting the data,`json.load` was used to load in the `Processed.json` file and also converting it to a python object using `json.loads` observations were made using the index of the sorted format e.g `Sorted_salary_commute[0]),Sorted_salary_commute[-1]` to view the lower and upper bounds of the `Sorted_salary_commute`. Conversion of the `Sorted_salary_commute` has been done using the json methon `json.dumps` while eventually writing it to the `commute.json` using the `json.dump` method\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198182d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "salary_commute_file = [] #Created a list to hold the salary_commute data\n",
    "with open('Processed.json', mode='r') as processed_file:#Opened the file in read mode\n",
    "    processed_json = json.load(processed_file)#Loaded the processed.json file\n",
    "    processed_object =json.loads(processed_json) #Converted \n",
    "    for user_col in processed_object:\n",
    "        if user_col[\"Commute Distance\"] <=1:\n",
    "            user_col[\"Salary-Commute Per Mile\"] = user_col[\"Yearly Pension (GBP)\"]\n",
    "        else:\n",
    "            user_col[\"Salary-Commute Per Mile\"] = user_col[\"Yearly Pension (GBP)\"] / user_col[\"Commute Distance\"]\n",
    "        salary_commute_file.append(user_col)\n",
    "    \n",
    "def sort_salary_commute(user_col):\n",
    "    return user_col[\"Salary-Commute Per Mile\"]\n",
    "\n",
    "Sorted_salary_commute = sorted(salary_commute_file, key= sort_salary_commute, reverse = False)\n",
    "print(Sorted_salary_commute[0])\n",
    "print(Sorted_salary_commute[-1])\n",
    "sorted_salarycommute_json = json.dumps(Sorted_salary_commute)\n",
    "with open('commute.json', mode='w') as commute_file:\n",
    "    commute_json = json.dump(sorted_salarycommute_json, commute_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c5839f",
   "metadata": {},
   "source": [
    "# Section 2: Data Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cafd99f",
   "metadata": {},
   "source": [
    "## Importing the required libraries for the data visualization\n",
    "The required libraries for data visualization needed for this section are; `pandas`, `seaborn`,`matplotlib` and will be imported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c16977",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd #Pandas library will be used for data analysis and manipulations in dataframe structure\n",
    "import seaborn as sns #This library will be used for graphical visualization of the data\n",
    "import matplotlib.pyplot as plt #Contains a lot of plotting utilities for graphical visualization\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "586ad84b",
   "metadata": {},
   "source": [
    "## Reading in the file and subsetting Salary and Age data series (Question 1)\n",
    "Read in the file using a pandas library function `read_csv` and also checked for nans using pandas method `isna()` and then, summed up the values using pandas function `sum()` to check for the total value of nans in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aadcaa17",
   "metadata": {},
   "outputs": [],
   "source": [
    "acw_data = pd.read_csv('acw_user_data.csv') #reading in the acw_data using the csv function read_csv\n",
    "salary_age_series=acw_data[['Yearly Salary (GBP)', 'Age (Years)']] #subsetting salary and age from the acw_data\n",
    "salary_age_series.isna().sum() #Checking for missing values and nans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5862c52",
   "metadata": {},
   "source": [
    "## Finding the Mean Salary (Yearly) (Question 1)\n",
    "The mean salary is gotten firstly, by subsetting `Yearly Salary (GBP)` from `salary_age_series` while using the pandas library fuction `mean()` to find the mean and assigning it to a variable `mean_salary` while formatting the result of `mean_salary` to 2 decimal places."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750b99a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_salary=salary_age_series['Yearly Salary (GBP)'].mean() #Applying the pandas library function mean()to find the mean on the subset data\n",
    "print(f'The mean of the yearly salary is £{mean_salary:,.2f}') #printing out the result of mean_salary to 2 decimal places"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131c8de0",
   "metadata": {},
   "source": [
    "## Finding the Median Age (Yearly) \n",
    "\n",
    "The median age is gotten firstly, by subsetting `Age (Years)` from `salary_age_series` while using the pandas library fuction `median()` to find the median and assigning it to a variable `median_age` while formatting the result of `median_age` to `0` decimal places."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2218b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "median_age = salary_age_series['Age (Years)'].median() #Using the pandas library function median() to find the median on the subset data\n",
    "\n",
    "print( f'The median of the age data series is {median_age:.0f}') #printing the result and rounding to 0 decimal places"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb28c65",
   "metadata": {},
   "source": [
    "##  a. Age, calculating how many bins would be required for a bin_width of 5.  ( Question 2)\n",
    "Calculated the number of bins that will be required for a `binwidth` of `5`, setting the `binwidth` allows `seaborn` to automatically calculate the number of bins that will be required.`sns.displot(data=salary_age_series['Age (Years)'], binwidth=5, height=5.5, aspect=2)` is used to carry out the plotting using a `facetgrid` plot such as `displot` to visualize the data. Also, setting the title of the plot using `fig.suptitle` and the label for the y-axis using `set_ylabels`. `plt.show` is used to visualize the plot.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d295591c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using a displot to create a facetgrid of the distribution plot of the age subset data using a binwidth of 5\n",
    "age_dplt = sns.displot(data=salary_age_series['Age (Years)'], binwidth=5, height=5.5, aspect=2)\n",
    "#Created a title for the plot using the fig.suptitle\n",
    "age_dplt.fig.suptitle(\"Distribution of Age using a binwidth of 5\", y=1.0, fontsize=12)\n",
    "#added a label to the y-axis for clarity using the set_ylabels\n",
    "age_dplt.set_ylabels(\"Frequency of Age (Years)\")\n",
    "plt.show() #This is used to display the output of the plot\n",
    "print(\"\") #Created some space\n",
    "#Description of the observation of the plot\n",
    "print(\"Fig 1.0: For a binwidth of 5, seaborn generated a total of 15 bins for our Age (Years) dataset as seen above\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b5c9d6",
   "metadata": {},
   "source": [
    "## b. Dependents, fixing data errors with seaborn itself \n",
    "\n",
    "A data cleaning of our Dependants column will be carried out in order to make it suitable for further analysis of our data. A data subsetting to find out some key information of the `Dependants` column, using methods such as `count()` to know the number of non-null values and `isna()` to find out the number of null values to be corrected and applying the pandas function `sum()` to get the total values of nans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd2656e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dependant_series=acw_data['Dependants'] #subsetting to generate the dependants column\n",
    "print(f'Total number of non-null:{Dependant_series.count()}') #checking the total count of non-null values\n",
    "print(f'Total number of nan values:{Dependant_series.isna().sum()}') #checking the total number of nans \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03480d7a",
   "metadata": {},
   "source": [
    "## Fixing the Data errors in the Dependants data series\n",
    "Checking for all the unique values in the `Dependants` column using the pandas library method `unique()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84375f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking for all unique values in the dependant column\n",
    "print(f\" Unique values of Dependants:{acw_data['Dependants'].unique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6ed9b4",
   "metadata": {},
   "source": [
    "## Finding the mode of the dependants column\n",
    "The mode of the dependans column will be used to fill in the missing values in the dependants column using the pandas library function `mode()` to find the mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82567685",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding the mode to fill missing values\n",
    "print(f\" The mode of Dependants:{acw_data['Dependants'].mode()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc9fb97",
   "metadata": {},
   "source": [
    "## Filling missing values\n",
    "The nans have been replaced with the mode of the dependants column using pandas library method `fillna()` to fill in the missing values and specifying `inplace =True` to effect the changes in the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7d7443",
   "metadata": {},
   "outputs": [],
   "source": [
    "acw_data['Dependants'].fillna( value=2.0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de75fff",
   "metadata": {},
   "source": [
    "## Observation of the dependants column\n",
    "It is now observed that there are no missing values in the dependants column which shows that the data errors have been corrected. Pandas methods such as `count()` and `isna` were used to observe the dependants column while applying the pandas function `sum()` to check the total number of missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc02cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking for non-null values\n",
    "print(f'Total number of non-null:{Dependant_series.count()}')\n",
    "#Checking for missing values\n",
    "print(f'Total number of nan values:{Dependant_series.isna().sum()}') \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e02af1be",
   "metadata": {},
   "source": [
    "### Plotting the Dependant column after fixing the data errors\n",
    "After fixing the erros in the dependants column, a plotting of the distribution of data in the dependants column has been done to visualize the data parsing in some parameters such as `bins`, `height` and `aspect` to the `facetgrid` `displot` while setting the plot title using `fig.suptitle` and the y-axis label using `set_ylabels`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980b2141",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Created a facetgrid distribution plot\n",
    "dependant_dplt = sns.displot(data=acw_data['Dependants'], bins=5, height=5.5, aspect=2)\n",
    "#Set a title for the plot\n",
    "dependant_dplt.fig.suptitle(\"Dependants distribution\", y=1.0, fontsize=12)\n",
    "#Set a label for the y-axis\n",
    "dependant_dplt.set_ylabels(\"Frequency of Dependants\")\n",
    "plt.show() #Display the plot\n",
    "# A description of the plot\n",
    "print(\"Fig 1.2: The x-axis shows the data points distribution of the Dependants column,while the y-xis shows the frequency of the dependants column\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d3ae3a",
   "metadata": {},
   "source": [
    "## c. Age (of default bins), conditioned on Marital Status\n",
    "Using the facetgrid `displot` to visualize the data of age conditioned on marital status. This is achieved by parsing in the parameter `hue`on marital status to set the condition. The x-axis will contain the data points of age while the y-axis shows the frequency of age. A plot title has been created using `fig.suptitle` and the y-axis labeled appropriately using `set_ylabels`, `plt.show` is used to display the plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3c0ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Created a facetgrid distribution plot and conditioned it on marital status\n",
    "age_marital_dplt = sns.displot(data=acw_data, x= 'Age (Years)', hue ='Marital Status')\n",
    "#Created a title for the plot\n",
    "age_marital_dplt.fig.suptitle(' Univariate plot of Age (Years) conditioned on Marital status',y=1.0, fontsize=12)\n",
    "#Labled the y-xis for clarity\n",
    "age_marital_dplt.set_ylabels(\"Frequency of Age (Years)\")\n",
    "#Displays the plot\n",
    "plt.show()\n",
    "#Description of the plot\n",
    "print(\"Fig 1.3: The x-axis shows the data points distribution of the Age (Years) column with default bins,while the y-xis shows the frequency of the Age (Years) column conditioned on marital status\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61eba598",
   "metadata": {},
   "source": [
    "## Perform multivariate plots with the following data attributes (Question 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cec887c",
   "metadata": {},
   "source": [
    "### a. Commuted distance against salary\n",
    "Used a `relplot` which is a more generalized plotting function to establish the relationship between `Distance Commuted to Work (miles)` and `Yearly Salary (GBP)`, also setting the title of the plot using `plt.title` while displaying the plot using `plt.show()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46725e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Used a relplot which is a generalized plotting function to create the plot\n",
    "commute_distance_salary_rlpt = sns.relplot(data=acw_data, x=\"Distance Commuted to Work (miles)\", y=\"Yearly Salary (GBP)\", height=5.5, aspect=2)\n",
    "#Set a title for the plot\n",
    "plt.title(\"commute distance from work and their Yearly Salary\")\n",
    "#Displayed the plot\n",
    "plt.show()\n",
    "#Description about the plot\n",
    "print(\"Fig 1.4: The figure above depicts the distance taking to commute to work and how much earned yearly depending on the distance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0845c9ca",
   "metadata": {},
   "source": [
    "## b. Age against Salary \n",
    "Used a `relplot` which is a more generalized plotting function to establish the relationship between `Age (Years)` and `Yearly Salary (GBP)`, also setting the title of the plot using `plt.title` while displaying the plot using `plt.show()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db13c174",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Used a relplot which is a generalized plotting function to create the plot\n",
    "age_salary_rlpt = sns.relplot(data=acw_data, x=\"Age (Years)\", y=\"Yearly Salary (GBP)\", height=5.5, aspect=2)\n",
    "#Set a title for the plot\n",
    "plt.title(\"Age (Years) against Yearly Salary\")\n",
    "#Displays the plot\n",
    "plt.show()\n",
    "#Description about the plot\n",
    "print(\"Fig 1.5: Using a relplot in the above graph which is a more generalized plotting function to show the relationship between age and salary, although the visualization does not say much\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a748b8b",
   "metadata": {},
   "source": [
    "## Showing where the line of best fit occured among the data points.\n",
    "An `implot` to show the line of best fit in the data points distribution has been used to make more meaning of the data while using `plt.title` to set the title of the plot and `plt.show` to display the plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bea9d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#An implot has been used to derive more meaning from the data points\n",
    "age_salary_plt = sns.lmplot(data=acw_data, x=\"Age (Years)\", y=\"Yearly Salary (GBP)\", height=5.5, aspect=2)\n",
    "#Sets a title for the plot\n",
    "plt.title(\"Age (Years) against Yearly Salary\")\n",
    "#Displays the plot\n",
    "plt.show()\n",
    "#Description about the plot\n",
    "print(\"Fig 1.5: Using an implot function to show an observation where the line of best fit maps a significant relationship of the data points\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "791ea0d4",
   "metadata": {},
   "source": [
    "### c. Age against Salary conditioned by Dependants\n",
    "An `implot` to show the line of best fit in the data points distribution has been used to make more meaning of the data while using the `hue` parameter to state a condition using the Dependants data. Also,`plt.title` to set the title of the plot and `plt.show` to display the plot.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52a858e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#An implot has been used to derive more meaning from the data points conditioned on the dependants data\n",
    "age_salary_dependants_implt = sns.lmplot(data=acw_data, x=\"Age (Years)\", y=\"Yearly Salary (GBP)\", height=5.5, aspect=2, hue='Dependants')\n",
    "# Sets a title for the plot\n",
    "plt.title(\"Age (Years) against Yearly Salary\")\n",
    "#Displays the plot\n",
    "plt.show()\n",
    "#Description of the plot\n",
    "print(\"Fig 1.5: Using an implot function to show an observation where the line of best fit maps a significant relationship of the data points conditioned on the Dependants column\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2681587",
   "metadata": {},
   "source": [
    "## Saving all the plots generated (Question 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb93878",
   "metadata": {},
   "outputs": [],
   "source": [
    "age_dplt.savefig(\"./age_dplt.png\") #Univariate saved plot for age\n",
    "dependant_dplt.savefig(\"./dependant_dplt.png\") #Univariate saved plot for dependants to show data corrections made\n",
    "age_marital_dplt.savefig(\"./age_marital_dplt.png\") #Univariate saved plot for age conditioned on marital status\n",
    "#Multivariate saved plot of commuted distance on salary\n",
    "commute_distance_salary_rlpt.savefig(\"./commute_distance_salary_rlpt.png\") \n",
    "#Multivariate saved plot of age against salary\n",
    "age_salary_rlpt.savefig(\"./age_salary_rlpt.png\")\n",
    "#Multivariate saved plot of age against salary showing the line of best fit of the data points\n",
    "age_salary_plt.savefig(\"./age_salary_plt.png\") \n",
    "#Multivariate saved plot of age against salary conditioned on dependants\n",
    "age_salary_dependants_implt.savefig(\"./age_salary_dependants_implt.png\") \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
